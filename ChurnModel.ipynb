{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "540877c9",
   "metadata": {},
   "source": [
    "# RED NEURONAL ARTIFICIAL\n",
    "## CHURN MODEL BANK\n",
    "\n",
    "El objetivo principal de este proyecto es analizar **10.000 datos de clientes en un banco** que tenia una tasa de abandono creciente y así pronosticar que clientes actuales también podrían abandonar dicho banco para así contactar con ellos. De modo que hago un pronóstico usando el módulo **Tensorflow** en Python en el IDE Spyder de Anaconda.\n",
    "\n",
    "\n",
    "### LIBRERIAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cfa212b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89f5d5b",
   "metadata": {},
   "source": [
    "### PATH Y VISUALIZACIÓN DE DATOS\n",
    "\n",
    "Visualizamos los datos de nuestro dataset y vemos que no tenga valores vacios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8c4b01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           10000 non-null  int64  \n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(2), int64(9), object(3)\n",
      "memory usage: 1.1+ MB\n",
      "None\n",
      "\n",
      "\n",
      "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
      "0          1    15634602  Hargrave          619    France  Female   42   \n",
      "1          2    15647311      Hill          608     Spain  Female   41   \n",
      "2          3    15619304      Onio          502    France  Female   42   \n",
      "3          4    15701354      Boni          699    France  Female   39   \n",
      "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
      "\n",
      "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
      "0       2       0.00              1          1               1   \n",
      "1       1   83807.86              1          0               1   \n",
      "2       8  159660.80              3          1               0   \n",
      "3       1       0.00              2          0               0   \n",
      "4       2  125510.82              1          1               1   \n",
      "\n",
      "   EstimatedSalary  Exited  \n",
      "0        101348.88       1  \n",
      "1        112542.58       0  \n",
      "2        113931.57       1  \n",
      "3         93826.63       0  \n",
      "4         79084.10       0  \n",
      "\n",
      "\n",
      " VALORES NULOS EN LAS COLUMNAS\n",
      "RowNumber          0\n",
      "CustomerId         0\n",
      "Surname            0\n",
      "CreditScore        0\n",
      "Geography          0\n",
      "Gender             0\n",
      "Age                0\n",
      "Tenure             0\n",
      "Balance            0\n",
      "NumOfProducts      0\n",
      "HasCrCard          0\n",
      "IsActiveMember     0\n",
      "EstimatedSalary    0\n",
      "Exited             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# PATH\n",
    "path = \"C:/Users/USUARIO/Desktop/CursoML/Data/\"\n",
    "data_client= pd.read_csv(path + \"Churn_Modelling.csv\")\n",
    "print(data_client.info())  # Son 10.000 datos\n",
    "print(\"\\n\")\n",
    "print(data_client.head())\n",
    "print(\"\\n\\n\" + \" VALORES NULOS EN LAS COLUMNAS\")\n",
    "print(data_client.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b2e511",
   "metadata": {},
   "source": [
    "### PREPROCESADO DE DATOS\n",
    "\n",
    "Almacenamos solamente las columnas que realmente tienen valores relevantes para nuestro algoritmo ya que por ejemplo las columnas **\"RowNumber\", \"CustomerId\" y \"Surname\"** no van a tener un peso estadístico en el problema y son irrelevantes. Entonces tomamos los siguientes datos:\n",
    "- La X, con las columnas desde las 3º posición hasta la penúltima. Siendo estos los valores independientes.\n",
    "- La Y, con la columna de valores booleanos de que un cliente se vaya o no del banco. Siendo este el valor dependiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3bb8337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocesado de Datos\n",
    "X = data_client.iloc[:, 3:-1].values # Valores independientes como edad, balance, activos, etc\n",
    "Y = data_client.iloc[:, -1].values # Valor booleano si se van o no, dependiente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a83b78",
   "metadata": {},
   "source": [
    "### TRANSFORMACIÓN DE DATOS\n",
    "\n",
    "En nuestro dataset existen variables tipo texto (String) como **\"Geography\"** y **\"Gender\"** y hay que transformar este texto en variables categoricas utlizando un codificador para que asi nuestro modelo sea capaz de reconocerlas. En este proyecto se han utilizado 2 formas:\n",
    "- labelEnconder \n",
    "- ColumnTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8bfa792f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[619 'France' 'Female' ... 1 1 101348.88]\n",
      " [608 'Spain' 'Female' ... 0 1 112542.58]\n",
      " [502 'France' 'Female' ... 1 0 113931.57]\n",
      " ...\n",
      " [709 'France' 'Female' ... 0 1 42085.58]\n",
      " [772 'Germany' 'Male' ... 1 0 92888.52]\n",
      " [792 'France' 'Female' ... 1 0 38190.78]]\n",
      "[[619 'France' 0 ... 1 1 101348.88]\n",
      " [608 'Spain' 0 ... 0 1 112542.58]\n",
      " [502 'France' 0 ... 1 0 113931.57]\n",
      " ...\n",
      " [709 'France' 0 ... 0 1 42085.58]\n",
      " [772 'Germany' 1 ... 1 0 92888.52]\n",
      " [792 'France' 0 ... 1 0 38190.78]]\n"
     ]
    }
   ],
   "source": [
    "# Transformamos las columna Gender que ahora está en la posición nº2 en el dataset X\n",
    "print(X)\n",
    "le = LabelEncoder()\n",
    "X[:, 2] = le.fit_transform(X[:, 2])\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83d0d156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0 0.0 1.0 ... 1 1 101348.88]\n",
      " [1.0 0.0 0.0 ... 0 1 112542.58]\n",
      " [1.0 0.0 1.0 ... 1 0 113931.57]\n",
      " ...\n",
      " [1.0 0.0 1.0 ... 0 1 42085.58]\n",
      " [0.0 1.0 0.0 ... 1 0 92888.52]\n",
      " [1.0 0.0 1.0 ... 1 0 38190.78]]\n"
     ]
    }
   ],
   "source": [
    "# MAS NUEVO COLUMTRANSFORMER\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2954d1c3",
   "metadata": {},
   "source": [
    "### TRAIN Y TEST\n",
    "\n",
    "Después de limpiar, preprocesar los datos, considerar que columnas son irrelavantes para nuestro modelo y transformar nuestros dato tipo texto a numérico ahora ya se pasaría a la fase de división de datos, es decir, considerar cuanto porcentaje de datos del dataset sería para entrenar nuestro modelo y el otro para testearlo y verificar su precisión. Normalmente:\n",
    "- TRAIN, tiene el 80% de datos del dataset original ya que cuanto más datos más comprobaciones realizará y más fiable será.\n",
    "- TEST, tiene el 20% de datos del dataset original y con él se mide la precisión.\n",
    "\n",
    "Como sería un proceso muy laborioso hacerlo manualmente con está gran cantidad de datos hay una función en Python del modulo sklearn llamada **train_test_split** que nos facilita esta división de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d8324199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividimos los datos usando la funcion train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=(0))\n",
    "\n",
    "# Escalado de variables, para agilizar el resultado \n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5f3846",
   "metadata": {},
   "source": [
    "### RED NEURONAL ARTIFICIAL\n",
    "\n",
    "Cuando ya tenemos nuestro conjunto de datos para entrenar y testear hay que crear nuetro modelo de red neuronal. En este caso, he creado un  modelo secuencial con el modulo **TensorFlow** utilizando **keras**. Creamos sus capas con sus nodos y la función sigmoide de salida que analizará los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "18638894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir la red neuronal artificial con keras del modelo secuencial\n",
    "RNA = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f7004291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capas de entrada y salida\n",
    "# 1º Capa de inputs\n",
    "RNA.add(tf.keras.layers.Dense(units=6, activation='relu'))\n",
    "# 2º Capa oculta de 6 nodos\n",
    "RNA.add(tf.keras.layers.Dense(units=6, activation='relu'))\n",
    "# Ultima capa de salidad, con funcion sigmoide\n",
    "RNA.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1a14f6",
   "metadata": {},
   "source": [
    "### ENTRENAMOS EL MODELO\n",
    "\n",
    "Después de haberse ejecutado nuestro modelo 100 veces, en su última repetición nuestro modelo tiene una precisión para predecir si un cliente se va del dataset train del **86'27%**.\n",
    "- Epoch 100/100\n",
    "250/250 [==============================] - 1s 2ms/step - loss: 0.3355 - **accuracy: 0.8627**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4c6f3588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 2s 3ms/step - loss: 0.6354 - accuracy: 0.6464\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4730 - accuracy: 0.8058\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4378 - accuracy: 0.8163\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4232 - accuracy: 0.8224\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4158 - accuracy: 0.8254\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4107 - accuracy: 0.8251\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4060 - accuracy: 0.8276\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4023 - accuracy: 0.8281\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3989 - accuracy: 0.8299\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3947 - accuracy: 0.8317\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3911 - accuracy: 0.8331\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3882 - accuracy: 0.8334\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3855 - accuracy: 0.8332\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3828 - accuracy: 0.8338\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3799 - accuracy: 0.8340\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3775 - accuracy: 0.8351\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3753 - accuracy: 0.8349\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3727 - accuracy: 0.8361\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3711 - accuracy: 0.8344\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3687 - accuracy: 0.8356\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3671 - accuracy: 0.8338\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3652 - accuracy: 0.8347\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3639 - accuracy: 0.8336\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3621 - accuracy: 0.8415\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3617 - accuracy: 0.8469\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3603 - accuracy: 0.8505\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3590 - accuracy: 0.8522\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3579 - accuracy: 0.8533\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3574 - accuracy: 0.8534\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3561 - accuracy: 0.8540\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3555 - accuracy: 0.8537\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3544 - accuracy: 0.8549\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3544 - accuracy: 0.8549\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3531 - accuracy: 0.8551\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3524 - accuracy: 0.8586\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3516 - accuracy: 0.8558\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3510 - accuracy: 0.8551\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3503 - accuracy: 0.8584\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3499 - accuracy: 0.8577\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3490 - accuracy: 0.8584\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3486 - accuracy: 0.8591\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3479 - accuracy: 0.8585\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3478 - accuracy: 0.8587\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3475 - accuracy: 0.8608\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3470 - accuracy: 0.8620\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3461 - accuracy: 0.8619\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3457 - accuracy: 0.8621\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3457 - accuracy: 0.8596\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3453 - accuracy: 0.8608\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3451 - accuracy: 0.8618\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3448 - accuracy: 0.8601\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3443 - accuracy: 0.8608\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3436 - accuracy: 0.8622\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3437 - accuracy: 0.8621\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3431 - accuracy: 0.8611\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3430 - accuracy: 0.8615\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3422 - accuracy: 0.8618\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3424 - accuracy: 0.8630\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3420 - accuracy: 0.8619\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3415 - accuracy: 0.8620\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3409 - accuracy: 0.8620\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3410 - accuracy: 0.8627\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3412 - accuracy: 0.8618\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3408 - accuracy: 0.8606\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3406 - accuracy: 0.8602\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3401 - accuracy: 0.8637\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3400 - accuracy: 0.8633\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.3401 - accuracy: 0.8627\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3396 - accuracy: 0.8625\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3399 - accuracy: 0.8626\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3390 - accuracy: 0.8630\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3391 - accuracy: 0.8622\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3394 - accuracy: 0.8625\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3382 - accuracy: 0.8624\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3384 - accuracy: 0.8622\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3377 - accuracy: 0.8627\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3382 - accuracy: 0.8624\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3389 - accuracy: 0.8621\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3375 - accuracy: 0.8635\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3383 - accuracy: 0.8618\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3372 - accuracy: 0.8644\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3374 - accuracy: 0.8637\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3380 - accuracy: 0.8634\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3370 - accuracy: 0.8646\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3372 - accuracy: 0.8643\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3374 - accuracy: 0.8616\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3364 - accuracy: 0.8633\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3369 - accuracy: 0.8635\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3369 - accuracy: 0.8621\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3366 - accuracy: 0.8648\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3363 - accuracy: 0.8640\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3362 - accuracy: 0.8648\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3365 - accuracy: 0.8630\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3362 - accuracy: 0.8620\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3356 - accuracy: 0.8658\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3361 - accuracy: 0.8627\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3357 - accuracy: 0.8626\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3351 - accuracy: 0.8636\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3348 - accuracy: 0.8635\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3355 - accuracy: 0.8627\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24acd62f708>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compilamos y ajustamos el modelo\n",
    "RNA.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "RNA.fit(X_train, y_train, batch_size = 32, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740429c5",
   "metadata": {},
   "source": [
    "### TESTING DEL MODELO ENTRENADO\n",
    "\n",
    "Con nuestro modelo entrenado ya podemos hacer una predicción de nuestro conjunto de datos de TEST que la RNA no ha analizado en ningun momento y así comprobar con este si realmente funciona correctamente nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "443ff7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [0 1]\n",
      " [0 0]\n",
      " ...\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prediccion de los resultados\n",
    "y_pred = RNA.predict(X_test)\n",
    "y_pred = (y_pred > 0.5) # Cuota intermedia del 50% que podria abandonar y pasamos a bool para comparar con la matriz\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))\n",
    "print(\"\\n\\n\")\n",
    "#MEJOR VISUALIZARLO EN SPYDER SE VE MEJOR EL CONJUNTO DE DATOS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "da7da0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MATRIZ DE CONFUSION\n",
      "[[1539   56]\n",
      " [ 221  184]]\n"
     ]
    }
   ],
   "source": [
    "# Elaborar una matriz de confunsion para evaluar los datos\n",
    "print('MATRIZ DE CONFUSION')\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac547bc",
   "metadata": {},
   "source": [
    "### Conclusión\n",
    "\n",
    "Nuestra RNA es capaz de predecir **correctamente** del modelo de testing (alrededor de 2000 datos) que **1539 son verdaderos positivos y 184 son verdaderos negativos siendo predicciones correctas** y **alrededor de 221 y 56 son falsos positivos y negativos** , es decir, ha acertado correctamente 1539+184 clientes (tanto que se quedan como que se iran) de los datos del TEST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "16da4e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del Testing \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "86.15"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Precision del testing\n",
    "print(\"Precision del Testing \" )\n",
    "(1539+184)/2000 * 100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
